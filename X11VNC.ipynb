{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c8eeadd-aca3-43b2-b946-7ed25dba0804",
   "metadata": {},
   "source": [
    "# Initialize the vnc working environment, only need to do this for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166db29e-d927-4e22-8af0-1521234195d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo DEBIAN_FRONTEND=noninteractive apt install lightdm x11vnc -y\n",
    "! sudo sh -c 'echo \"/usr/sbin/lightdm\" > /etc/X11/default-display-manager'\n",
    "! echo \"set shared/default-x-display-manager lightdm\" | sudo debconf-communicate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d669f99a-be0d-421a-ac05-d23d2b25bde4",
   "metadata": {},
   "source": [
    "# Remember to restart the device after the installation is complete, execute the following command, or turn off the power and restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5df831-ac9b-4b10-b01f-f811032a3780",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo reboot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "706399e9-479b-47e4-9152-b731ba841270",
   "metadata": {},
   "source": [
    "# Run the following command to start the vnc service, and enter the ip of jetson nano through the vnc viewer to log in to the remote desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7708a-24c3-4b38-85e7-1a057852b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "! x11vnc -forever -display :0 -auth guess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2d2675f",
   "metadata": {},
   "source": [
    "# Use camera-capture\n",
    "```bash\n",
    "mkdir -p /home/nvidia/jetson-inference/python/training/detection/ssd/data/custom\n",
    "camera-capture /dev/video0\n",
    "\n",
    "# set resolution\n",
    "camera-capture /dev/video0 --input-width=640 --input-height=480\n",
    "\n",
    "# set frame rate\n",
    "camera-capture /dev/video0 --input-rate=10\n",
    "```\n",
    "\n",
    "## use directory\n",
    "```bash\n",
    "#dataset path is set to: \n",
    "/home/nvidia/jetson-inference/python/training/detection/ssd/data/custom\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5be7478-05b6-4728-b6a6-63a298ba3374",
   "metadata": {},
   "source": [
    "# use docker desktop client to training\n",
    "\n",
    "1. Download the latest docker client from the docker.com website\n",
    "2. Double-click the client to install, and restart after the installation is complete\n",
    "3. If you are using it for the first time and the network environment is not good, you can download the tf.tar image in advance and import it into docker. The pytorch.tar image address: [pytorch.tar](https://netorg639112-my.sharepoint.com/:u:/g/personal/jack_wang_integem_com1/EYLyfiGFA9pDolh--WUt_DYBqE8C203INvq99Fj0I4nGbA?e=ifglj8), [the specific process](#import-image)\n",
    "4. Open cmd on the desktop and run\n",
    "> Copy and paste all the content below into the terminal and press enter\n",
    "```bash\n",
    "docker run --name nvidia --rm -it -p 8888:8888 integem/pytorch:latest bash -c \"cd /home && wget https://raw.githubusercontent.com/integemjack/tf-online/main/ssd.ipynb && jupyter lab --allow-root\"\n",
    "```\n",
    "\n",
    "5. Get the token address, for example:\n",
    "\n",
    "```bash\n",
    "# http://127.0.0.1:8888/lab?token=21941d36957a9aa8e7401f930d3cbf7fe8232733b4ebcb5d\n",
    "# Hold down ctrl and click on the link to open jupyter lab\n",
    "```\n",
    "\n",
    "## ------------------------------------------------------------------------\n",
    "\n",
    "# export image\n",
    "\n",
    "Open cmd and run the following command to generate a pytorch.tar image file in the set directory\n",
    "\n",
    "```bash\n",
    "docker save -o <pytorch.tar absolute path> integem/pytorch:latest\n",
    "```\n",
    "\n",
    "# import image\n",
    "\n",
    "You can download the pytorch.tar file through [pytorch.tar](https://netorg639112-my.sharepoint.com/:u:/g/personal/jack_wang_integem_com1/EYLyfiGFA9pDolh--WUt_DYBqE8C203INvq99Fj0I4nGbA?e=ifglj8), or you can get pytorch.tar through the above export\n",
    "\n",
    "```bash\n",
    "docker load -i <pytorch.tar absolute path>\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffed46f0",
   "metadata": {},
   "source": [
    "# The last step, after completing all the steps on the local jupyter, perform the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a262e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to convert the model into an onnx file in nano, please execute the following\n",
    "%cd /home/nvidia/jetson-inference/python/training/detection/ssd\n",
    "! python3 onnx_export.py --model-dir=models/custom"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
