{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "414892a2-3d66-405a-be1e-44935106b2ff",
   "metadata": {},
   "source": [
    "# 初始化在终端\n",
    "\n",
    "```bash\n",
    "sudo apt install lightdm -y\n",
    "sudo reboot\n",
    "\n",
    "sudo apt install x11vnc -y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7708a-24c3-4b38-85e7-1a057852b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "! x11vnc -forever -display :0 -auth guess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2d2675f",
   "metadata": {},
   "source": [
    "# Use camera-capture\n",
    "```bash\n",
    "mkdir -p /home/nvidia/jetson-inference/python/training/detection/ssd/data/custom\n",
    "camera-capture /dev/video0\n",
    "```\n",
    "\n",
    "## use directory\n",
    "```bash\n",
    "#dataset path is set to: \n",
    "/home/nvidia/jetson-inference/python/training/detection/ssd/data/custom\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5be7478-05b6-4728-b6a6-63a298ba3374",
   "metadata": {},
   "source": [
    "# use docker desktop client to training\n",
    "\n",
    "1. Download the latest docker client from the docker.com website\n",
    "2. Double-click the client to install, and restart after the installation is complete\n",
    "3. If you are using it for the first time and the network environment is not good, you can download the tf.tar image in advance and import it into docker. The pytorch.tar image address: [pytorch.tar](https://netorg639112-my.sharepoint.com/:u:/g/personal/jack_wang_integem_com1/EYLyfiGFA9pDolh--WUt_DYBqE8C203INvq99Fj0I4nGbA?e=ifglj8), [the specific process](#import-image)\n",
    "4. Open cmd on the desktop and run\n",
    "> Copy and paste all the content below into the terminal and press enter\n",
    "```bash\n",
    "docker run --name nvidia --rm -it -p 8888:8888 integem/pytorch:latest bash -c \"cd /home && wget https://raw.githubusercontent.com/integemjack/tf-online/main/ssd.ipynb && jupyter lab --allow-root\"\n",
    "```\n",
    "\n",
    "5. Get the token address, for example:\n",
    "\n",
    "```bash\n",
    "# http://127.0.0.1:8888/lab?token=21941d36957a9aa8e7401f930d3cbf7fe8232733b4ebcb5d\n",
    "# Hold down ctrl and click on the link to open jupyter lab\n",
    "```\n",
    "\n",
    "## ------------------------------------------------------------------------\n",
    "\n",
    "# export image\n",
    "\n",
    "Open cmd and run the following command to generate a pytorch.tar image file in the set directory\n",
    "\n",
    "```bash\n",
    "docker save -o <pytorch.tar absolute path> integem/pytorch:latest\n",
    "```\n",
    "\n",
    "# import image\n",
    "\n",
    "You can download the pytorch.tar file through [pytorch.tar](https://netorg639112-my.sharepoint.com/:u:/g/personal/jack_wang_integem_com1/EYLyfiGFA9pDolh--WUt_DYBqE8C203INvq99Fj0I4nGbA?e=ifglj8), or you can get pytorch.tar through the above export\n",
    "\n",
    "```bash\n",
    "docker load -i <pytorch.tar absolute path>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a262e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to convert the model into an onnx file in nano, please execute the following\n",
    "%cd /home/jetson-inference/python/training/detection/ssd\n",
    "! python3 onnx_export.py --model-dir=models/custom"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
